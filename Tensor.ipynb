{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-09T17:12:50.665751Z",
     "start_time": "2024-06-09T17:12:47.507111Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T17:12:50.721360Z",
     "start_time": "2024-06-09T17:12:50.665751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "apple = pd.read_csv(\"AAPL.csv\")\n",
    "amazon = pd.read_csv(\"AMZN.csv\")\n",
    "google = pd.read_csv(\"GOOG.csv\")\n",
    "google_l = pd.read_csv(\"GOOGL.csv\")\n",
    "microsoft = pd.read_csv(\"MSFT.csv\")\n",
    "tesla = pd.read_csv(\"TSLA.csv\")"
   ],
   "id": "9ad0ab42dc874fff",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T17:12:50.731837Z",
     "start_time": "2024-06-09T17:12:50.721360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def paint(data):\n",
    "    data = data.iloc[::-1]\n",
    "    data = data.reset_index(drop=True)\n",
    "    data['Label'] = np.where(data['adj close'].shift(-1) > data['adj close'], 1, 0)\n",
    "    #data['Label'] = (data['close'] > data['open']).astype(int)\n",
    "    return data\n",
    "apple = paint(apple)\n",
    "amazon = paint(amazon)\n",
    "google = paint(google)\n",
    "google_l = paint(google_l)\n",
    "microsoft = paint(microsoft)\n",
    "tesla = paint(tesla)\n",
    "\n",
    "# print(apple)"
   ],
   "id": "dbeaebbac8cdfc6a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T17:13:03.240351Z",
     "start_time": "2024-06-09T17:12:50.731837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tweets = pd.read_csv(\"D:\\johnny的文件夹\\FDU 课程\\大二下\\大数据商务分析\\Final project\\data\\Tweet\\Tweet.csv\")\n",
    "company_tweets = pd.read_csv(\n",
    "    \"D:\\johnny的文件夹\\FDU 课程\\大二下\\大数据商务分析\\Final project\\data\\Tweet\\Company_Tweet.csv\")\n",
    "tweets.drop('writer', axis=1, inplace=True)\n",
    "df_tweets = pd.merge(tweets, company_tweets, on='tweet_id', how='left')\n",
    "df_tweets['post_date'] = pd.to_datetime(df_tweets['post_date'], unit='s')\n",
    "df_tweets['post_date'] = df_tweets['post_date'].dt.strftime('%Y-%m-%d')\n",
    "df_tweets.drop('tweet_id', axis=1, inplace=True)\n"
   ],
   "id": "2226d1312c2ff4e0",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T17:29:55.140996Z",
     "start_time": "2024-06-09T17:29:52.083386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def explore(company,df):\n",
    "    df1 = df[df['ticker_symbol'] == company]\n",
    "    comment = df1.groupby('post_date')['comment_num'].sum()\n",
    "    like = df1.groupby('post_date')['like_num'].sum()\n",
    "    retweet = df1.groupby('post_date')['retweet_num'].sum()\n",
    "    df1 = pd.concat([comment, like, retweet], axis=1)\n",
    "    df1 = df1.reset_index()\n",
    "    return df1\n",
    "apple_tweets = explore('AAPL',df_tweets)\n",
    "amazon_tweets = explore('AMZN',df_tweets)\n",
    "google_tweets = explore('GOOG',df_tweets)\n",
    "googlel_tweets = explore('GOOGL',df_tweets)\n",
    "microsoft_tweets = explore('MSFT',df_tweets)\n",
    "tesla_tweets = explore('TSLA',df_tweets)\n",
    "\n",
    "# print(apple_tweets)"
   ],
   "id": "6050ab18a6c567cb",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T17:29:56.972867Z",
     "start_time": "2024-06-09T17:29:56.916665Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def make_stock(stock, tweet):\n",
    "    stock['date'] = pd.to_datetime(stock['date'])\n",
    "    tweet['post_date'] = pd.to_datetime(tweet['post_date'])\n",
    "\n",
    "    start_date = '2015-01-01'\n",
    "    end_date = '2019-12-31'\n",
    "    stock = stock.loc[(stock['date'] >= start_date) & (stock['date'] <= end_date)]\n",
    "    tweet.rename(columns={'post_date': 'date'}, inplace=True)\n",
    "    result = pd.merge(stock, tweet, on='date', how='left')\n",
    "    return result\n",
    "#结合了stock price和tweets的数据在此处！\n",
    "apple_stock = make_stock(apple, apple_tweets).dropna()\n",
    "amazon_stock = make_stock(amazon, amazon_tweets).dropna()\n",
    "google_stock = make_stock(google, google_tweets).dropna()\n",
    "googlel_stock = make_stock(google_l, googlel_tweets).dropna()\n",
    "microsoft_stock = make_stock(microsoft, microsoft_tweets).dropna()\n",
    "tesla_stock = make_stock(tesla, tesla_tweets).dropna()\n"
   ],
   "id": "3ab69db1350da37d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T17:30:08.992669Z",
     "start_time": "2024-06-09T17:30:08.979359Z"
    }
   },
   "cell_type": "code",
   "source": "apple_stock",
   "id": "460a4baa65c943da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           date        open        high         low       close   adj close  \\\n",
       "0    2015-01-02  111.389999  111.440002  107.349998  109.330002  100.216454   \n",
       "1    2015-01-05  108.290001  108.650002  105.410004  106.250000   97.393181   \n",
       "2    2015-01-06  106.540001  107.430000  104.629997  106.260002   97.402374   \n",
       "3    2015-01-07  107.199997  108.199997  106.699997  107.750000   98.768150   \n",
       "4    2015-01-08  109.230003  112.150002  108.699997  111.889999  102.563072   \n",
       "...         ...         ...         ...         ...         ...         ...   \n",
       "1253 2019-12-24  284.690002  284.890015  282.920013  284.269989  283.596924   \n",
       "1254 2019-12-26  284.820007  289.980011  284.700012  289.910004  289.223602   \n",
       "1255 2019-12-27  291.119995  293.970001  288.119995  289.799988  289.113831   \n",
       "1256 2019-12-30  289.459991  292.690002  285.220001  291.519989  290.829773   \n",
       "1257 2019-12-31  289.929993  293.679993  289.519989  293.649994  292.954712   \n",
       "\n",
       "        volume  Label  comment_num  like_num  retweet_num  \n",
       "0     53204600      0        102.0     437.0       1834.0  \n",
       "1     64285500      1        145.0     593.0        413.0  \n",
       "2     65797100      1        120.0     468.0        227.0  \n",
       "3     40105900      1        102.0     567.0        210.0  \n",
       "4     59364500      1        272.0     857.0        498.0  \n",
       "...        ...    ...          ...       ...          ...  \n",
       "1253  12119700      1        142.0     998.0        208.0  \n",
       "1254  23280300      0        258.0    1945.0        410.0  \n",
       "1255  36566500      1        152.0     892.0        150.0  \n",
       "1256  36028600      1        334.0    2149.0        773.0  \n",
       "1257  25201400      1        199.0    1753.0        336.0  \n",
       "\n",
       "[1255 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adj close</th>\n",
       "      <th>volume</th>\n",
       "      <th>Label</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>like_num</th>\n",
       "      <th>retweet_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>111.389999</td>\n",
       "      <td>111.440002</td>\n",
       "      <td>107.349998</td>\n",
       "      <td>109.330002</td>\n",
       "      <td>100.216454</td>\n",
       "      <td>53204600</td>\n",
       "      <td>0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>1834.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>108.290001</td>\n",
       "      <td>108.650002</td>\n",
       "      <td>105.410004</td>\n",
       "      <td>106.250000</td>\n",
       "      <td>97.393181</td>\n",
       "      <td>64285500</td>\n",
       "      <td>1</td>\n",
       "      <td>145.0</td>\n",
       "      <td>593.0</td>\n",
       "      <td>413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>106.540001</td>\n",
       "      <td>107.430000</td>\n",
       "      <td>104.629997</td>\n",
       "      <td>106.260002</td>\n",
       "      <td>97.402374</td>\n",
       "      <td>65797100</td>\n",
       "      <td>1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>107.199997</td>\n",
       "      <td>108.199997</td>\n",
       "      <td>106.699997</td>\n",
       "      <td>107.750000</td>\n",
       "      <td>98.768150</td>\n",
       "      <td>40105900</td>\n",
       "      <td>1</td>\n",
       "      <td>102.0</td>\n",
       "      <td>567.0</td>\n",
       "      <td>210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>109.230003</td>\n",
       "      <td>112.150002</td>\n",
       "      <td>108.699997</td>\n",
       "      <td>111.889999</td>\n",
       "      <td>102.563072</td>\n",
       "      <td>59364500</td>\n",
       "      <td>1</td>\n",
       "      <td>272.0</td>\n",
       "      <td>857.0</td>\n",
       "      <td>498.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>2019-12-24</td>\n",
       "      <td>284.690002</td>\n",
       "      <td>284.890015</td>\n",
       "      <td>282.920013</td>\n",
       "      <td>284.269989</td>\n",
       "      <td>283.596924</td>\n",
       "      <td>12119700</td>\n",
       "      <td>1</td>\n",
       "      <td>142.0</td>\n",
       "      <td>998.0</td>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>284.820007</td>\n",
       "      <td>289.980011</td>\n",
       "      <td>284.700012</td>\n",
       "      <td>289.910004</td>\n",
       "      <td>289.223602</td>\n",
       "      <td>23280300</td>\n",
       "      <td>0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>1945.0</td>\n",
       "      <td>410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>291.119995</td>\n",
       "      <td>293.970001</td>\n",
       "      <td>288.119995</td>\n",
       "      <td>289.799988</td>\n",
       "      <td>289.113831</td>\n",
       "      <td>36566500</td>\n",
       "      <td>1</td>\n",
       "      <td>152.0</td>\n",
       "      <td>892.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>289.459991</td>\n",
       "      <td>292.690002</td>\n",
       "      <td>285.220001</td>\n",
       "      <td>291.519989</td>\n",
       "      <td>290.829773</td>\n",
       "      <td>36028600</td>\n",
       "      <td>1</td>\n",
       "      <td>334.0</td>\n",
       "      <td>2149.0</td>\n",
       "      <td>773.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>289.929993</td>\n",
       "      <td>293.679993</td>\n",
       "      <td>289.519989</td>\n",
       "      <td>293.649994</td>\n",
       "      <td>292.954712</td>\n",
       "      <td>25201400</td>\n",
       "      <td>1</td>\n",
       "      <td>199.0</td>\n",
       "      <td>1753.0</td>\n",
       "      <td>336.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1255 rows × 11 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T12:19:58.476059Z",
     "start_time": "2024-06-07T12:19:58.458645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "closing = apple_stock['adj close'].values.reshape(-1,1)\n",
    "scaler = MinMaxScaler()\n",
    "scaled_prices = scaler.fit_transform(closing)\n",
    "\n",
    "print(scaled_prices)"
   ],
   "id": "3296e20db0d07751",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07231139]\n",
      " [0.0587224 ]\n",
      " [0.05876665]\n",
      " ...\n",
      " [0.98151305]\n",
      " [0.98977223]\n",
      " [1.        ]]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T12:19:08.572851Z",
     "start_time": "2024-06-07T12:19:08.552156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_size = int(len(scaled_prices) * 0.8)\n",
    "train_prices = scaled_prices[:train_size]\n",
    "test_prices = scaled_prices[train_size:]\n",
    "\n",
    "print(train_prices)"
   ],
   "id": "43ddbe383b3bc1a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07231139]\n",
      " [0.0587224 ]\n",
      " [0.05876665]\n",
      " ...\n",
      " [0.32903098]\n",
      " [0.3361744 ]\n",
      " [0.33702584]]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T12:30:17.831760Z",
     "start_time": "2024-06-07T12:30:17.781571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create(data,step=1):\n",
    "    X,y = [],[]\n",
    "    for i in range(len(data)-step):\n",
    "        X.append(data[i:(i+step),0])\n",
    "        y.append([int(data[i + step + j + 1] > data[i + step + j] if i + step + j + 1 < len(data) else 0) for j in range(7)])\n",
    "    return np.array(X),np.array(y)\n",
    "X_train, y_train = create(train_prices,10)\n",
    "X_test, y_test = create(test_prices,10)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "print(y_train.shape)"
   ],
   "id": "f53b4d9f9abe3b00",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(994, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnn\\AppData\\Local\\Temp\\ipykernel_856\\939061209.py:5: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  y.append([int(data[i + step + j + 1] > data[i + step + j] if i + step + j + 1 < len(data) else 0) for j in range(7)])\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T12:34:39.424625Z",
     "start_time": "2024-06-07T12:34:34.058089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], 1)))\n",
    "model.add(LSTM(units=50))\n",
    "# model.add(Dense(units = 128))\n",
    "model.add(Dense(units=7))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.compile(optimizer='adam', loss='mse',\n",
    "              metrics=[tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128)"
   ],
   "id": "507673f1a2be29e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnn\\PycharmProjects\\Deep Learning\\venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 13ms/step - loss: 0.4854 - precision_7: 0.0000e+00 - recall_7: 0.0000e+00\n",
      "Epoch 2/10\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 0.4037 - precision_7: 0.2007 - recall_7: 0.0038\n",
      "Epoch 3/10\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 19ms/step - loss: 0.2913 - precision_7: 0.5020 - recall_7: 0.3269\n",
      "Epoch 4/10\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 0.2758 - precision_7: 0.5059 - recall_7: 0.4422\n",
      "Epoch 5/10\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 0.2688 - precision_7: 0.4967 - recall_7: 0.2898\n",
      "Epoch 6/10\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 0.2591 - precision_7: 0.5172 - recall_7: 0.4601\n",
      "Epoch 7/10\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step - loss: 0.2562 - precision_7: 0.5054 - recall_7: 0.4789\n",
      "Epoch 8/10\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 0.2530 - precision_7: 0.5158 - recall_7: 0.4523\n",
      "Epoch 9/10\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 0.2520 - precision_7: 0.5097 - recall_7: 0.5523\n",
      "Epoch 10/10\n",
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step - loss: 0.2508 - precision_7: 0.5165 - recall_7: 0.6365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1fdb232c910>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-07T12:34:44.634911Z",
     "start_time": "2024-06-07T12:34:43.080122Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss,precision,recall = model.evaluate(X_test, y_test)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "print(precision, recall, f1)"
   ],
   "id": "80f9d2f71f8d5cd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 6ms/step - loss: 0.2454 - precision_7: 0.5895 - recall_7: 1.0000\n",
      "0.5696502923965454 1.0 0.7258308365321324\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 包括更多的LSTM",
   "id": "e1e0ead171e1f2e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T12:13:53.116739Z",
     "start_time": "2024-06-06T12:13:53.104934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "closing = apple_stock['adj close'].values.reshape(-1,1)\n",
    "like = apple_stock['like_num'].values.reshape(-1,1)\n",
    "comment = apple_stock['comment_num'].values.reshape(-1,1)\n",
    "retweet = apple_stock['retweet_num'].values.reshape(-1,1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "closing = scaler.fit_transform(closing)\n",
    "like = scaler.fit_transform(like)\n",
    "comment = scaler.fit_transform(comment)\n",
    "retweet = scaler.fit_transform(retweet)"
   ],
   "id": "d937976a0dbec217",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T12:13:53.132155Z",
     "start_time": "2024-06-06T12:13:53.116739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "stack_np = np.column_stack((closing,like,comment,retweet))\n",
    "X = pd.DataFrame(stack_np, columns=['closing','like','comment','retweet'])\n",
    "y = apple_stock['Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)"
   ],
   "id": "1ea34a1b27752af3",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T12:13:55.066645Z",
     "start_time": "2024-06-06T12:13:53.132155Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model2 = Sequential()\n",
    "model2.add(LSTM(units=50, return_sequences=True))\n",
    "model2.add(LSTM(units=50))\n",
    "model2.add(Dense(units=1))\n",
    "model2.compile(loss='mse', optimizer='adam')\n",
    "model2.compile(optimizer='adam', loss='mse',\n",
    "              metrics=[tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64)"
   ],
   "id": "597764b51c92c1cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - loss: 0.3778 - precision_9: 0.2529 - recall_9: 0.0481        \n",
      "Epoch 2/10\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.2636 - precision_9: 0.5380 - recall_9: 0.7640 \n",
      "Epoch 3/10\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2509 - precision_9: 0.5990 - recall_9: 0.3558\n",
      "Epoch 4/10\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.2504 - precision_9: 0.5286 - recall_9: 0.7505\n",
      "Epoch 5/10\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2501 - precision_9: 0.4990 - recall_9: 0.4974\n",
      "Epoch 6/10\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2472 - precision_9: 0.5409 - recall_9: 0.8667\n",
      "Epoch 7/10\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.2520 - precision_9: 0.5386 - recall_9: 0.3346 \n",
      "Epoch 8/10\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2500 - precision_9: 0.5372 - recall_9: 0.9184 \n",
      "Epoch 9/10\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2502 - precision_9: 0.5295 - recall_9: 0.5147\n",
      "Epoch 10/10\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.2496 - precision_9: 0.5234 - recall_9: 0.5859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e7865f5d90>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T12:13:55.466046Z",
     "start_time": "2024-06-06T12:13:55.067653Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss,precision,recall = model.evaluate(X_test, y_test)\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "print(precision, recall, f1)"
   ],
   "id": "adb7f87ac6165dc6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m8/8\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.2521 - precision_9: 0.5257 - recall_9: 0.5605  \n",
      "0.5259740352630615 0.5625 0.543624166035286\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-06T12:13:55.471390Z",
     "start_time": "2024-06-06T12:13:55.466046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 模型大小差距 Bert。 Github里有参考\n",
    "# 轻量Bert只处理推特数据，另一个分支处理股票数据（LSTM），再合并\n",
    "# word2vec：把文本转换为向量 扔到LSTM里 常用\n",
    "# 如今这些包比较成熟，背后的原理不再关键\n",
    "# grid search 超参 各种资料 （learning rate）\n",
    "# 可以放入探索过程"
   ],
   "id": "55f629d5037eb9bd",
   "outputs": [],
   "execution_count": 70
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
